{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11fde21",
   "metadata": {},
   "source": [
    "# Multimodal video search using CLIP and LanceDB\n",
    "We used LanceDB to store frames every thirty seconds and the title of 13000+ videos, 5 random from each top category from the Youtube 8M dataset. \n",
    "Then, we used the CLIP model to embed frames and titles together. With LanceDB, we can perform embedding, keyword, and SQL search on these videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb1627",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -U lancedb\n",
    "!pip install --quiet gradio transformers torch torchvision duckdb\n",
    "!pip install tantivy@git+https://github.com/quickwit-oss/tantivy-py#164adc87e1a033117001cf70e38c82a53014d985"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d53ade3",
   "metadata": {},
   "source": [
    "## First run setup: Download data and pre-process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b7e97f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import lancedb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ba75742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "--2023-08-11 23:00:34--  https://vectordb-recipes.s3.us-west-2.amazonaws.com/multimodal_video_lance.tar.gz\n",
      "Resolving vectordb-recipes.s3.us-west-2.amazonaws.com (vectordb-recipes.s3.us-west-2.amazonaws.com)... 52.92.209.2, 3.5.81.172, 52.92.179.82, ...\n",
      "Connecting to vectordb-recipes.s3.us-west-2.amazonaws.com (vectordb-recipes.s3.us-west-2.amazonaws.com)|52.92.209.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 239974228 (229M) [application/x-gzip]\n",
      "Saving to: ‘multimodal_video_lance.tar.gz’\n",
      "\n",
      "multimodal_video_la 100%[===================>] 228.86M  5.18MB/s    in 82s     \n",
      "\n",
      "2023-08-11 23:01:56 (2.79 MB/s) - ‘multimodal_video_lance.tar.gz’ saved [239974228/239974228]\n",
      "\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "x multimodal_video.lance/\n",
      "x multimodal_video.lance/.DS_Store\n",
      "x multimodal_video.lance/_versions/\n",
      "x multimodal_video.lance/_latest.manifest\n",
      "x multimodal_video.lance/data/\n",
      "x multimodal_video.lance/_indices/\n",
      "x multimodal_video.lance/_indices/tantivy/\n",
      "x multimodal_video.lance/_indices/tantivy/9b278a8cf1c14b7f8c4c92a40bb75163.store\n",
      "x multimodal_video.lance/_indices/tantivy/e0a7ab7a679242bb93b9e451252bb0ab.idx\n",
      "x multimodal_video.lance/_indices/tantivy/a0fc72fda7d24f8b9042ea17b111d00e.term\n",
      "x multimodal_video.lance/_indices/tantivy/2d0c8f633d1e4bdf8dfebb72a577da01.pos\n",
      "x multimodal_video.lance/_indices/tantivy/d6777856977d44c0a7be9249e27ecbf9.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/2130bc17dd0f4563a9578658b4ca8725.term\n",
      "x multimodal_video.lance/_indices/tantivy/9b278a8cf1c14b7f8c4c92a40bb75163.fast\n",
      "x multimodal_video.lance/_indices/tantivy/34bc7d3e86b34d78b50bde2ed0d78142.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/9b278a8cf1c14b7f8c4c92a40bb75163.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/e0a7ab7a679242bb93b9e451252bb0ab.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/a0fc72fda7d24f8b9042ea17b111d00e.fast\n",
      "x multimodal_video.lance/_indices/tantivy/2130bc17dd0f4563a9578658b4ca8725.fast\n",
      "x multimodal_video.lance/_indices/tantivy/5ae00c69b7a54e2eb11b771cd589bdef.store\n",
      "x multimodal_video.lance/_indices/tantivy/9b278a8cf1c14b7f8c4c92a40bb75163.term\n",
      "x multimodal_video.lance/_indices/tantivy/ec2a0fec9b5644d0a1688909ae4ab401.idx\n",
      "x multimodal_video.lance/_indices/tantivy/2130bc17dd0f4563a9578658b4ca8725.pos\n",
      "x multimodal_video.lance/_indices/tantivy/.tantivy-meta.lock\n",
      "x multimodal_video.lance/_indices/tantivy/2d0c8f633d1e4bdf8dfebb72a577da01.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/a0fc72fda7d24f8b9042ea17b111d00e.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/5325ec58020041caa3445d73d265e7fb.pos\n",
      "x multimodal_video.lance/_indices/tantivy/a0fc72fda7d24f8b9042ea17b111d00e.pos\n",
      "x multimodal_video.lance/_indices/tantivy/d6777856977d44c0a7be9249e27ecbf9.pos\n",
      "x multimodal_video.lance/_indices/tantivy/2130bc17dd0f4563a9578658b4ca8725.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/3683f0cf34f94bfba076d75045148da3.term\n",
      "x multimodal_video.lance/_indices/tantivy/e0a7ab7a679242bb93b9e451252bb0ab.store\n",
      "x multimodal_video.lance/_indices/tantivy/34bc7d3e86b34d78b50bde2ed0d78142.pos\n",
      "x multimodal_video.lance/_indices/tantivy/9b278a8cf1c14b7f8c4c92a40bb75163.pos\n",
      "x multimodal_video.lance/_indices/tantivy/5ae00c69b7a54e2eb11b771cd589bdef.fast\n",
      "x multimodal_video.lance/_indices/tantivy/a6c6c3c429b041f59827f5ba80b82c8e.pos\n",
      "x multimodal_video.lance/_indices/tantivy/3683f0cf34f94bfba076d75045148da3.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/3683f0cf34f94bfba076d75045148da3.idx\n",
      "x multimodal_video.lance/_indices/tantivy/.tantivy-writer.lock\n",
      "x multimodal_video.lance/_indices/tantivy/5ae00c69b7a54e2eb11b771cd589bdef.term\n",
      "x multimodal_video.lance/_indices/tantivy/3683f0cf34f94bfba076d75045148da3.store\n",
      "x multimodal_video.lance/_indices/tantivy/a6c6c3c429b041f59827f5ba80b82c8e.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/5ae00c69b7a54e2eb11b771cd589bdef.pos\n",
      "x multimodal_video.lance/_indices/tantivy/af7082fa8060442095731134023712ef.idx\n",
      "x multimodal_video.lance/_indices/tantivy/5325ec58020041caa3445d73d265e7fb.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/3683f0cf34f94bfba076d75045148da3.fast\n",
      "x multimodal_video.lance/_indices/tantivy/d6777856977d44c0a7be9249e27ecbf9.fast\n",
      "x multimodal_video.lance/_indices/tantivy/2d0c8f633d1e4bdf8dfebb72a577da01.fast\n",
      "x multimodal_video.lance/_indices/tantivy/a6c6c3c429b041f59827f5ba80b82c8e.store\n",
      "x multimodal_video.lance/_indices/tantivy/2d0c8f633d1e4bdf8dfebb72a577da01.store\n",
      "x multimodal_video.lance/_indices/tantivy/e0a7ab7a679242bb93b9e451252bb0ab.fast\n",
      "x multimodal_video.lance/_indices/tantivy/e0a7ab7a679242bb93b9e451252bb0ab.pos\n",
      "x multimodal_video.lance/_indices/tantivy/af7082fa8060442095731134023712ef.fast\n",
      "x multimodal_video.lance/_indices/tantivy/5ae00c69b7a54e2eb11b771cd589bdef.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/5325ec58020041caa3445d73d265e7fb.fast\n",
      "x multimodal_video.lance/_indices/tantivy/2d0c8f633d1e4bdf8dfebb72a577da01.idx\n",
      "x multimodal_video.lance/_indices/tantivy/5325ec58020041caa3445d73d265e7fb.store\n",
      "x multimodal_video.lance/_indices/tantivy/af7082fa8060442095731134023712ef.term\n",
      "x multimodal_video.lance/_indices/tantivy/ec2a0fec9b5644d0a1688909ae4ab401.pos\n",
      "x multimodal_video.lance/_indices/tantivy/2130bc17dd0f4563a9578658b4ca8725.idx\n",
      "x multimodal_video.lance/_indices/tantivy/5325ec58020041caa3445d73d265e7fb.term\n",
      "x multimodal_video.lance/_indices/tantivy/d6777856977d44c0a7be9249e27ecbf9.store\n",
      "x multimodal_video.lance/_indices/tantivy/5325ec58020041caa3445d73d265e7fb.idx\n",
      "x multimodal_video.lance/_indices/tantivy/d6777856977d44c0a7be9249e27ecbf9.term\n",
      "x multimodal_video.lance/_indices/tantivy/2d0c8f633d1e4bdf8dfebb72a577da01.term\n",
      "x multimodal_video.lance/_indices/tantivy/ec2a0fec9b5644d0a1688909ae4ab401.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/e0a7ab7a679242bb93b9e451252bb0ab.term\n",
      "x multimodal_video.lance/_indices/tantivy/34bc7d3e86b34d78b50bde2ed0d78142.store\n",
      "x multimodal_video.lance/_indices/tantivy/34bc7d3e86b34d78b50bde2ed0d78142.fast\n",
      "x multimodal_video.lance/_indices/tantivy/d6777856977d44c0a7be9249e27ecbf9.idx\n",
      "x multimodal_video.lance/_indices/tantivy/2130bc17dd0f4563a9578658b4ca8725.store\n",
      "x multimodal_video.lance/_indices/tantivy/ec2a0fec9b5644d0a1688909ae4ab401.store\n",
      "x multimodal_video.lance/_indices/tantivy/a0fc72fda7d24f8b9042ea17b111d00e.idx\n",
      "x multimodal_video.lance/_indices/tantivy/af7082fa8060442095731134023712ef.store\n",
      "x multimodal_video.lance/_indices/tantivy/a0fc72fda7d24f8b9042ea17b111d00e.store\n",
      "x multimodal_video.lance/_indices/tantivy/a6c6c3c429b041f59827f5ba80b82c8e.idx\n",
      "x multimodal_video.lance/_indices/tantivy/af7082fa8060442095731134023712ef.fieldnorm\n",
      "x multimodal_video.lance/_indices/tantivy/ec2a0fec9b5644d0a1688909ae4ab401.term\n",
      "x multimodal_video.lance/_indices/tantivy/9b278a8cf1c14b7f8c4c92a40bb75163.idx\n",
      "x multimodal_video.lance/_indices/tantivy/34bc7d3e86b34d78b50bde2ed0d78142.idx\n",
      "x multimodal_video.lance/_indices/tantivy/.managed.json\n",
      "x multimodal_video.lance/_indices/tantivy/a6c6c3c429b041f59827f5ba80b82c8e.fast\n",
      "x multimodal_video.lance/_indices/tantivy/ec2a0fec9b5644d0a1688909ae4ab401.fast\n",
      "x multimodal_video.lance/_indices/tantivy/3683f0cf34f94bfba076d75045148da3.pos\n",
      "x multimodal_video.lance/_indices/tantivy/a6c6c3c429b041f59827f5ba80b82c8e.term\n",
      "x multimodal_video.lance/_indices/tantivy/34bc7d3e86b34d78b50bde2ed0d78142.term\n",
      "x multimodal_video.lance/_indices/tantivy/af7082fa8060442095731134023712ef.pos\n",
      "x multimodal_video.lance/_indices/tantivy/5ae00c69b7a54e2eb11b771cd589bdef.idx\n",
      "x multimodal_video.lance/_indices/tantivy/meta.json\n",
      "x multimodal_video.lance/data/43a4100e-575d-4bdd-9c47-df8acb14a577.lance\n",
      "x multimodal_video.lance/_versions/1.manifest\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "mv: rename multimodal_video.lance to data/video-lancedb/multimodal_video.lance: Directory not empty\n"
     ]
    }
   ],
   "source": [
    "!wget https://vectordb-recipes.s3.us-west-2.amazonaws.com/multimodal_video_lance.tar.gz\n",
    "!tar -xvf multimodal_video_lance.tar.gz\n",
    "!mkdir -p data/video-lancedb\n",
    "!mv multimodal_video.lance data/video-lancedb/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fcbf61",
   "metadata": {},
   "source": [
    "## Create / Open LanceDB Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3317a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect(\"data/video-lancedb\")\n",
    "tbl = db.open_table(\"multimodal_video\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4fc03",
   "metadata": {},
   "source": [
    "## Create CLIP embedding function for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8331d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPModel, CLIPProcessor, CLIPTokenizerFast\n",
    "\n",
    "MODEL_ID = \"openai/clip-vit-base-patch32\"\n",
    "\n",
    "tokenizer = CLIPTokenizerFast.from_pretrained(MODEL_ID)\n",
    "model = CLIPModel.from_pretrained(MODEL_ID)\n",
    "processor = CLIPProcessor.from_pretrained(MODEL_ID)\n",
    "\n",
    "def embed_func(query):\n",
    "    inputs = tokenizer([query], padding=True, return_tensors=\"pt\")\n",
    "    text_features = model.get_text_features(**inputs)\n",
    "    return text_features.detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d7a54",
   "metadata": {},
   "source": [
    "\n",
    "## Search functions for Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10b8de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_video_vectors(query):\n",
    "    emb = embed_func(query)\n",
    "    code = (\n",
    "        \"import lancedb\\n\"\n",
    "        \"db = lancedb.connect('data/video-lancedb')\\n\"\n",
    "        \"tbl = db.open_table('multimodal_video')\\n\\n\"\n",
    "        f\"embedding = embed_func('{query}')\\n\"\n",
    "        \"tbl.search(embedding).limit(9).to_df()\"\n",
    "    )\n",
    "    return (_extract(tbl.search(emb).limit(9).to_df()), code)\n",
    "\n",
    "def find_video_keywords(query):\n",
    "    code = (\n",
    "        \"import lancedb\\n\"\n",
    "        \"db = lancedb.connect('data/video-lancedb')\\n\"\n",
    "        \"tbl = db.open_table('multimodal_video')\\n\\n\"\n",
    "        f\"tbl.search('{query}').limit(9).to_df()\"\n",
    "    )\n",
    "    return (_extract(tbl.search(query).limit(9).to_df()), code)\n",
    "\n",
    "def find_video_sql(query):\n",
    "    code = (\n",
    "        \"import lancedb\\n\"\n",
    "        \"import duckdb\\n\"\n",
    "        \"db = lancedb.connect('data/video-lancedb')\\n\"\n",
    "        \"tbl = db.open_table('multimodal_video')\\n\\n\"\n",
    "        \"videos = tbl.to_lance()\\n\"\n",
    "        f\"duckdb.sql('{query}').to_df()\"\n",
    "    )    \n",
    "    videos = tbl.to_lance()\n",
    "    return (_extract(duckdb.sql(query).to_df()), code)\n",
    "\n",
    "def _extract(df):\n",
    "    video_id_col = \"video_id\"\n",
    "    start_time_col = \"start_time\"\n",
    "    grid_html = '<div style=\"display: grid; grid-template-columns: repeat(3, 1fr); grid-gap: 20px;\">'\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        iframe_code = f'<iframe width=\"100%\" height=\"315\" src=\"https://www.youtube.com/embed/{row[video_id_col]}?start={str(row[start_time_col])}\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>'\n",
    "        grid_html += f'<div style=\"width: 100%;\">{iframe_code}</div>'\n",
    "\n",
    "    grid_html += '</div>'\n",
    "    return grid_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aaf19b",
   "metadata": {},
   "source": [
    "## Setup Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6f40300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ExecNode(Projection): channel closed\n",
      "ExecNode(Projection): channel closed\n",
      "ExecNode(Take): channel closed\n",
      "ExecNode(Take): channel closed\n",
      "ExecNode(Projection): channel closed\n",
      "ExecNode(Projection): channel closed\n",
      "ExecNode(Take): channel closed\n",
      "ExecNode(Take): channel closed\n",
      "ExecNode(Projection): channel closed\n",
      "ExecNode(Projection): channel closed\n",
      "ExecNode(Take): channel closed\n",
      "ExecNode(Take): channel closed\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/gradio/routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/gradio/utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/0d/54vc82d97537gkrc254fy5bm0000gn/T/ipykernel_89793/2874212455.py\", line 31, in find_video_sql\n",
      "    return (_extract(duckdb.sql(query).to_df()), code)\n",
      "duckdb.CatalogException: Catalog Error: Table with name multimodal_video does not exist!\n",
      "Did you mean \"temp.information_schema.tables\"?\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/gradio/routes.py\", line 442, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1392, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/gradio/blocks.py\", line 1097, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/Users/tevinwang/Documents/repos/tevinwang/vectordb-recipes/venv/lib/python3.10/site-packages/gradio/utils.py\", line 703, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/var/folders/0d/54vc82d97537gkrc254fy5bm0000gn/T/ipykernel_89793/2874212455.py\", line 31, in find_video_sql\n",
      "    return (_extract(duckdb.sql(query).to_df()), code)\n",
      "duckdb.CatalogException: Catalog Error: Table with name multimodal_video does not exist!\n",
      "Did you mean \"temp.information_schema.tables\"?\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown('''\n",
    "            # Multimodal video search using CLIP and LanceDB\n",
    "            We used LanceDB to store frames every thirty seconds and the title of 13000+ videos, 5 random from each top category from the Youtube 8M dataset. \n",
    "            Then, we used the CLIP model to embed frames and titles together. With LanceDB, we can perform embedding, keyword, and SQL search on these videos.\n",
    "            ''')\n",
    "    with gr.Row():\n",
    "        with gr.Tab(\"Embeddings\"):\n",
    "            vector_query = gr.Textbox(value=\"retro gaming\", show_label=False)\n",
    "            b1 = gr.Button(\"Submit\")\n",
    "        with gr.Tab(\"Keywords\"):\n",
    "            keyword_query = gr.Textbox(value=\"ninja turtles\", show_label=False)\n",
    "            b2 = gr.Button(\"Submit\")\n",
    "        with gr.Tab(\"SQL\"):\n",
    "            sql_query = gr.Textbox(value=\"SELECT DISTINCT video_id, * from videos WHERE start_time > 0 LIMIT 9\", show_label=False)\n",
    "            b3 = gr.Button(\"Submit\")\n",
    "    with gr.Row():\n",
    "        code = gr.Code(label=\"Code\", language=\"python\")\n",
    "    with gr.Row():\n",
    "        gallery = gr.HTML()\n",
    "        \n",
    "    b1.click(find_video_vectors, inputs=vector_query, outputs=[gallery, code])\n",
    "    b2.click(find_video_keywords, inputs=keyword_query, outputs=[gallery, code])\n",
    "    b3.click(find_video_sql, inputs=sql_query, outputs=[gallery, code])\n",
    "    \n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "511a7c77cb034b09af5465c01316a0f4bb20176d139e60e6d7915f9a637a5037"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
